{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48d2b3ba-089c-494a-bd79-9a616b108d63",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "I will use a distilled version of GPT2, configured as a regression model, to predict log scores directly. The output of this model could be combined in multiple ways with the other features identified in the data_analysis notebook to potentially achieve even better results.\n",
    "\n",
    "Multiple model arrangements could be attempted before deciding on a specifc setup. The above is only a rationale for my starting point.\n",
    "\n",
    "I will use Huggingface's distilled version of the GPT2 LLM (https://huggingface.co/distilgpt2). This is not a SOTA model, but it can be handled by my humble personal laptop in reasonable time.\n",
    "\n",
    "# tl;dr\n",
    "\n",
    "- Distilled GPT2 achieves much better performance (as measured by R2) than handcrafted regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8c22705-08f7-42f6-9dcc-dbfa40a4e05f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilgpt2 were not used when initializing GPT2ForSequenceClassification: ['lm_head.weight']\n",
      "- This IS expected if you are initializing GPT2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at distilgpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import torch\n",
    "\n",
    "BASE_MODEL = 'distilgpt2'\n",
    "LEARNING_RATE = 2e-5\n",
    "MAX_LENGTH = 256 # could be larger with more resources, would ensure we consider long posts\n",
    "BATCH_SIZE = 16 # could be larger with more resources, would ensure we never over adjust on small samples\n",
    "EPOCHS = 5 # needs to be small to finish in reasonable time\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL) \n",
    "tokenizer.pad_token = tokenizer.eos_token_id # distilgpt2 tokenizer does not have a default padding token\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(BASE_MODEL, num_labels=1)\n",
    "model.config.pad_token_id = model.config.eos_token_id # distilgpt2 model needs to conform to the tokenizer\n",
    "model.resize_token_embeddings(len(tokenizer)) # distilgpt2 model needs to conform to the tokenizer\n",
    "\n",
    "def compute_metrics_for_regression(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    labels = labels.reshape(-1, 1)\n",
    "    \n",
    "    mse = mean_squared_error(labels, logits)\n",
    "    mae = mean_absolute_error(labels, logits)\n",
    "    r2 = r2_score(labels, logits)\n",
    "    \n",
    "    return {\"mse\": mse, \"mae\": mae, \"r2\": r2}\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./models/distilgpt2-fine-tuned-regression\",\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    metric_for_best_model=\"r2\",\n",
    "    load_best_model_at_end=True,\n",
    "    weight_decay=0.01,\n",
    "    optim=\"adamw_torch\"\n",
    ")\n",
    "\n",
    "\n",
    "class RegressionTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs[0][:, 0]\n",
    "        loss = torch.nn.functional.mse_loss(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "    \n",
    "def preprocess_function(df):\n",
    "    label = df[\"score\"] \n",
    "    examples = tokenizer(df[\"full_text\"], truncation=True, padding='max_length', max_length=MAX_LENGTH)\n",
    "\n",
    "    # Change this to real number\n",
    "    examples[\"label\"] = float(label)\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca761066-ae8b-4b21-868c-d097596ff07f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /Users/christianrodriguezmercado/.cache/huggingface/datasets/json/default-5c43c10a08bef696/0.0.0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00837f24743748d79979e73388fcabb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "662a8bb5d1084bfa8274fd9ac4d1f941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /Users/christianrodriguezmercado/.cache/huggingface/datasets/json/default-5c43c10a08bef696/0.0.0. Subsequent calls will reuse this data.\n",
      "Downloading and preparing dataset json/default to /Users/christianrodriguezmercado/.cache/huggingface/datasets/json/default-14b2a6691c4b4144/0.0.0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb9e20ff0700485e8d0d4c82a89ccfc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "499943ba6cdf40c19cc2c92b1be415d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /Users/christianrodriguezmercado/.cache/huggingface/datasets/json/default-14b2a6691c4b4144/0.0.0. Subsequent calls will reuse this data.\n",
      "Downloading and preparing dataset json/default to /Users/christianrodriguezmercado/.cache/huggingface/datasets/json/default-fe43cf30e363a20f/0.0.0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "478cb749c4724c21b4162fe7f314d670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a1dd1b061b743cd9c5e8334cd2a1e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /Users/christianrodriguezmercado/.cache/huggingface/datasets/json/default-fe43cf30e363a20f/0.0.0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['title', 'full_text', 'score'],\n",
       "     num_rows: 4804\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['title', 'full_text', 'score'],\n",
       "     num_rows: 719\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['title', 'full_text', 'score'],\n",
       "     num_rows: 1736\n",
       " }))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = Dataset.from_json(\"./data/reddit_scores_train.jsonlines\")\n",
    "val_ds = Dataset.from_json(\"./data/reddit_scores_val.jsonlines\")\n",
    "test_ds = Dataset.from_json(\"./data/reddit_scores_test.jsonlines\")\n",
    "\n",
    "train_ds, val_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d519f509-3ee0-4fd4-bd99-a4979ffa7471",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4804 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/719 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1736 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = {\"train\": train_ds, \"validation\": val_ds, \"test\": test_ds}\n",
    "\n",
    "for split in ds:\n",
    "    ds[split] = ds[split].map(preprocess_function, remove_columns=[\"title\", \"full_text\", \"score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42a9f9ea-bddf-418d-94e0-1531e6294efe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1505' max='1505' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1505/1505 1:27:22, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mse</th>\n",
       "      <th>Mae</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>8.238085</td>\n",
       "      <td>8.238084</td>\n",
       "      <td>2.216275</td>\n",
       "      <td>0.272116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>11.675300</td>\n",
       "      <td>8.399469</td>\n",
       "      <td>8.399471</td>\n",
       "      <td>2.068044</td>\n",
       "      <td>0.257857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11.675300</td>\n",
       "      <td>7.277102</td>\n",
       "      <td>7.277102</td>\n",
       "      <td>2.174073</td>\n",
       "      <td>0.357025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>8.925200</td>\n",
       "      <td>6.091055</td>\n",
       "      <td>6.091055</td>\n",
       "      <td>1.866863</td>\n",
       "      <td>0.461819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>7.477400</td>\n",
       "      <td>5.671689</td>\n",
       "      <td>5.671689</td>\n",
       "      <td>1.780632</td>\n",
       "      <td>0.498872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1505, training_loss=9.346669202785556, metrics={'train_runtime': 5245.649, 'train_samples_per_second': 4.579, 'train_steps_per_second': 0.287, 'total_flos': 1569115322449920.0, 'train_loss': 9.346669202785556, 'epoch': 5.0})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = RegressionTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    eval_dataset=ds[\"validation\"],\n",
    "    compute_metrics=compute_metrics_for_regression,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f80613-3724-4cbc-b5e0-fe7f5db72701",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "- Not surprisingly, even a non SOTA LLM achieves over 3x better performance than handcrafted features alone\n",
    "- The R2 of this initial model is almost 0.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
